{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f04dc476a53d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malexnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.alexnet(pretrained=False)\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from time import sleep\n",
    "def convert_angle(x,y):\n",
    "    if(y == 0):      #special case when y = 0 \n",
    "        if(x == 0):          #reach the destination\n",
    "            return None\n",
    "        elif(x > 0):     \n",
    "            return 90\n",
    "        else:\n",
    "            return -90\n",
    "    temp = x/y\n",
    "    if(y > 0): #in case from -90 to 90 degree\n",
    "        return math.degrees(math.atan(temp))\n",
    "    \n",
    "    else:\n",
    "        if(x > 0):  #case for 90 to 180 degree\n",
    "            return 180 - math.degrees(math.atan(temp))\n",
    "        else:       #case for -180 to -90 degree\n",
    "            return math.degrees(math.atan(temp)) - 180\n",
    "        \n",
    "def update_info_straight(x,y,curr_angle, time):    #for keep space\n",
    "    speed = 1       #currently defalut 1, can use calibration to change that\n",
    "    x = x + math.sin(math.radians(curr_angle)) * time * speed\n",
    "    y = y + math.cos(math.radians(curr_angle)) * time * speed\n",
    "\n",
    "    return True\n",
    "\n",
    "def reach_destination(curr_x, x, curr_y, y):  \n",
    "    distance_apart = math.sqrt((curr_x - x)**2 + (curr_y - y)**2)       #use to calculate the distance from the destination to current lcoation\n",
    "    \n",
    "    if(distance_apart < 1): #within a range, then it mean it is close to the destination, then it return true.\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def turn_left(leftspeed = 0.4, rightspeed = 0.6):    # use for easy control of the car\n",
    "    robot.set_motors(leftspeed, rightspeed)\n",
    "\n",
    "def turn_right(leftspeed = 0.6, rightspeed = 0.4):    \n",
    "    robot.set_motors(leftspeed, rightspeed)\n",
    "\n",
    "def spin_left(speed = 0.5):\n",
    "    robot.left(speed)\n",
    "\n",
    "def spin_right(speed = 0.5):\n",
    "    robot.right(speed)\n",
    "\n",
    "def straight(speed = 1):\n",
    "    robot.forward(speed)\n",
    "\n",
    "def check_angle(angle):     #use to convert the angle to be between -180 to 180 degree\n",
    "    if(angle > 180):\n",
    "        return -180 + angle - 180\n",
    "    elif(angle < -180):\n",
    "        return 180 + angle + 180\n",
    "    else:\n",
    "        return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "blocked_slider = widgets.FloatSlider(description='blocked', min=0.0, max=1.0, orientation='vertical')\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "display(image)\n",
    "display(widgets.HBox([image, blocked_slider]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()\n",
    "robot.stop()\n",
    "\n",
    "curr_x = 0          #use to keep track on the x of the car current status\n",
    "curr_y = 0          #use to keep track on the y of the car current status\n",
    "curr_angle = 0      #use to keep track on the angle of the car current status, range from -180 to 180. 0 indicate straight\n",
    "des_x = None\n",
    "des_y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "def update(change):\n",
    "    global blocked_slider, robot, curr_x, curr_y, curr_angle \n",
    "    global des_x, des_y\n",
    "    \n",
    "    if(reach_destination(curr_x, x, curr_y, y)):\n",
    "        break\n",
    "    x = change['new'] \n",
    "    x = preprocess(x)\n",
    "    y = model(x)\n",
    "    \n",
    "    # we apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)\n",
    "    y = F.softmax(y, dim=1)\n",
    "    \n",
    "    prob_blocked = float(y.flatten()[0])\n",
    "    \n",
    "    blocked_slider.value = prob_blocked\n",
    "    \n",
    "    if prob_blocked < 0.5: #if no object\n",
    "        target_angle = convert_angle(x - curr_x, y - curr_y)\n",
    "        angle_different = curr_angle - target_angle\n",
    "            if(abs(angle_different) > 2):#not pointing at the correct angle\n",
    "                #adjust to the left while going straight if angle is negative and right if angle is positive\n",
    "                if(angle_different < 0):\n",
    "                    robot.left(0.5)\n",
    "                else:\n",
    "                    robot.right(0.5)\n",
    "\n",
    "                time_to_turn = spin_time / abs(angle_different)     #calculate how long does the spin need to be\n",
    "\n",
    "                sleep(time_to_turn)     #sleep to wait until the car turn enough\n",
    "                curr_angle = target_angle    #x and y did not change, only the angle change to the target value in this case.\n",
    "                \n",
    "            else:\n",
    "                #go straight \n",
    "                straight()\n",
    "                sleep(0.1)\n",
    "                update_info_straight(curr_x,curr_y,curr_angle, 0.1)            \n",
    "            \n",
    "    else:\n",
    "        spin_left()\n",
    "        sleep(0.1)\n",
    "        curr_angle = check_angle(curr_angle - (time_to_turn/0.1) * 360)  #make sure the angle is between -180 to 180 degree\n",
    "        straight()\n",
    "        sleep(0.5)\n",
    "        update_info_straight(curr_x, curr_y,curr_angle,0.5)\n",
    "        \n",
    "    time.sleep(0.001)\n",
    "        \n",
    "update({'new': camera.value})  # we call the function once to intialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(update, names='value')  # this attaches the 'update' function to the 'value' traitlet of our camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve(update, names='value')\n",
    "robot.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
